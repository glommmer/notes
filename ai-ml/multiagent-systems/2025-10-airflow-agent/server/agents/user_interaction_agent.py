"""
User Interaction Agent - Communicates with user and gets feedback
"""

import logging
from typing import Dict, Any
from langchain_openai import ChatOpenAI, AzureChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from server.workflow.state import AgentState, AgentType
from server.config import settings

logger = logging.getLogger(__name__)


class UserInteractionAgent:
    """
    Agent responsible for user communication

    This agent:
    1. Presents analysis results to the user
    2. Asks clarifying questions
    3. Gets user approval for actions
    4. Handles user feedback
    """

    def __init__(self):
        """Initialize interaction agent"""
        self.agent_type = AgentType.INTERACTION

        # Initialize LLM for generating user-friendly messages
        self.llm = ChatOpenAI(
            model=settings.OPENAI_MODEL,
            temperature=0.5,
            api_key=settings.OPENAI_API_KEY,
            base_url=settings.OPENAI_BASE_URL,
        )

        # self.llm = AzureChatOpenAI(
        #     openai_api_key=settings.AZURE_OPENAI_API_KEY,
        #     azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
        #     azure_deployment=settings.AZURE_OPENAI_DEPLOYMENT,
        #     api_version=settings.AZURE_OPENAI_API_VERSION,
        #     temperature=0.5,
        #     # streaming=True,  # ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
        # )

    def __call__(self, state: AgentState) -> Dict[str, Any]:
        """
        Generate user interaction message

        Args:
            state: Current workflow state

        Returns:
            Updated state with user question
        """
        logger.info("ğŸ’¬ UserInteractionAgent: Preparing user interaction...")

        # Check if we already have user input
        # ì‚¬ìš©ì ì…ë ¥ì´ ì´ë¯¸ ìˆìœ¼ë©´ ë°”ë¡œ ì²˜ë¦¬
        if state.get("user_input"):
            logger.info("User input already provided, processing...")
            return self._process_user_input(state)

        if state.get("requires_user_input") and state.get("user_question"):
            logger.info("Already waiting for user input - no change")
            return {
                "current_agent": self.agent_type.value,  # ë‹¤ë¥¸ í•„ë“œ ë°˜í™˜ ì•ˆ í•¨ (ìƒíƒœ ìœ ì§€)
            }

        # Generate question for user
        # ì²« ë²ˆì§¸ ì§ˆë¬¸ ìƒì„±
        question = self._generate_user_question(state)

        # if not state.get("requires_user_input"):
        #     return {
        #         "user_question": question,
        #         "requires_user_input": True,  # â† ì²˜ìŒë§Œ!
        #         "current_agent": self.agent_type.value,
        #     }

        return {
            "user_question": question,
            "requires_user_input": True,
            "current_agent": self.agent_type.value,
        }

    def _generate_user_question(self, state: AgentState) -> str:
        """
        Generate user-friendly question based on analysis

        Args:
            state: Current workflow state

        Returns:
            User question string
        """
        dag_id = state.get("dag_id", "ì•Œ ìˆ˜ ì—†ìŒ")
        task_id = state.get("task_id", "ì•Œ ìˆ˜ ì—†ìŒ")
        dag_run_id = state.get("dag_run_id", "ì•Œ ìˆ˜ ì—†ìŒ")

        analysis_report = state.get("analysis_report", "")
        root_cause = state.get("root_cause", "ë¶„ì„ ì¤‘...")
        suggested_solution = state.get("suggested_solution", "")

        # Use LLM to create user-friendly summary
        try:
            prompt = ChatPromptTemplate.from_messages(
                [
                    (
                        "system",
                        """ë‹¹ì‹ ì€ ì¹œì ˆí•œ Airflow ëª¨ë‹ˆí„°ë§ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì—ê²Œ ì˜¤ë¥˜ ìƒí™©ì„ ì„¤ëª…í•˜ê³ , í•´ê²° ë°©ë²•ì„ ì œì•ˆí•˜ë©°, 
ë‹¤ìŒ ì•¡ì…˜ì— ëŒ€í•œ ìŠ¹ì¸ì„ ìš”ì²­í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

ë©”ì‹œì§€ëŠ” ë‹¤ìŒì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
1. ì˜¤ë¥˜ ìƒí™© ìš”ì•½ (ê°„ë‹¨ëª…ë£Œí•˜ê²Œ)
2. ê·¼ë³¸ ì›ì¸ ì„¤ëª…
3. ì œì•ˆí•˜ëŠ” í•´ê²° ë°©ë²•
4. ì‚¬ìš©ì ì•¡ì…˜ ì˜µì…˜ (ì¬ì‹¤í–‰, ìˆ˜ë™ ì²˜ë¦¬ ë“±)

ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ì€ 
ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
""",
                    ),
                    (
                        "human",
                        """ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ë³´ë‚¼ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

DAG: {dag_id}
Task: {task_id}
Run: {dag_run_id}

ê·¼ë³¸ ì›ì¸: {root_cause}

ë¶„ì„ ë³´ê³ ì„œ:
{analysis_report}

ì‚¬ìš©ìê°€ ì„ íƒí•  ìˆ˜ ìˆëŠ” ì˜µì…˜ì„ ëª…í™•íˆ ì œì‹œí•˜ê³ ,
ê° ì˜µì…˜ì˜ ì˜ë¯¸ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.
""",
                    ),
                ]
            )

            chain = prompt | self.llm

            response = chain.invoke(
                {
                    "dag_id": dag_id,
                    "task_id": task_id,
                    "dag_run_id": dag_run_id,
                    "root_cause": root_cause,
                    "analysis_report": analysis_report[:1000],  # Limit length
                }
            )

            message = response.content

        except Exception as e:
            logger.error(f"Error generating user message: {e}")
            # Fallback to simple message
            message = f"""
## ğŸš¨ Airflow Task ì‹¤íŒ¨ ê°ì§€

**DAG**: {dag_id}  
**Task**: {task_id}  
**Run ID**: {dag_run_id}

### ğŸ“Š ë¶„ì„ ê²°ê³¼
{root_cause}

### ğŸ’¡ ì œì•ˆ ì‚¬í•­
{suggested_solution}

"""

        # Add action options
        message += """

---

### ğŸ”§ ë‹¤ìŒ ì•¡ì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”:

1. **ì¬ì‹¤í–‰ (Clear & Retry)**: Taskë¥¼ Clearí•˜ì—¬ ìë™ìœ¼ë¡œ ì¬ì‹¤í–‰í•©ë‹ˆë‹¤.
2. **ìˆ˜ë™ ì²˜ë¦¬**: ì½”ë“œë‚˜ ì„¤ì •ì„ ìˆ˜ì •í•œ í›„ ì§ì ‘ ì²˜ë¦¬í•˜ê² ìŠµë‹ˆë‹¤.
3. **ë¶„ì„ ë³´ê³ ì„œ í™•ì¸**: ì „ì²´ ë¶„ì„ ë³´ê³ ì„œë¥¼ ë¨¼ì € í™•ì¸í•˜ê² ìŠµë‹ˆë‹¤.

ì–´ë–¤ ì•¡ì…˜ì„ ìˆ˜í–‰í• ê¹Œìš”?
"""

        return message

    def _process_user_input(self, state: AgentState) -> Dict[str, Any]:
        """
        Process user input and determine next action

        Args:
            state: State with user input

        Returns:
            Updated state with action decision
        """
        user_input = state.get("user_input", "").strip().lower()

        logger.info(f"Processing user input: {user_input}")

        # Parse user decision
        if any(
            keyword in user_input
            for keyword in ["ì¬ì‹¤í–‰", "clear", "retry", "ë‹¤ì‹œ", "1"]
        ):
            final_action = "CLEAR_TASK"
            action_message = "âœ… Taskë¥¼ Clearí•˜ì—¬ ì¬ì‹¤í–‰í•˜ê² ìŠµë‹ˆë‹¤."

        elif any(
            keyword in user_input
            for keyword in ["ìˆ˜ë™", "manual", "ì§ì ‘", "2", "ê±´ë„ˆë›°", "skip"]
        ):
            final_action = "SKIP"
            action_message = "â­ï¸  ìˆ˜ë™ ì²˜ë¦¬ë¥¼ ìœ„í•´ ê±´ë„ˆëœë‹ˆë‹¤."

        elif any(
            keyword in user_input
            for keyword in ["ë³´ê³ ì„œ", "ë¶„ì„", "report", "3", "í™•ì¸"]
        ):
            final_action = "SHOW_REPORT"
            action_message = "ğŸ“„ ì „ì²´ ë¶„ì„ ë³´ê³ ì„œë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."

        else:
            # Default: treat as request for more info
            final_action = "SHOW_REPORT"
            action_message = "ğŸ“„ ì…ë ¥ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì „ì²´ ë³´ê³ ì„œë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."

        return {
            "final_action": final_action,
            "action_result": action_message,
            "requires_user_input": False,
            "current_agent": self.agent_type.value,
        }
