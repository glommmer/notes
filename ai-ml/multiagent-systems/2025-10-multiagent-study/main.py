import os
import time
import requests
import typing as t
from functools import wraps
from collections import defaultdict
from typing import Literal
from typing_extensions import TypedDict
from dotenv import load_dotenv
from langchain_openai import AzureChatOpenAI
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langgraph.types import Command
from langgraph.prebuilt import create_react_agent
from langgraph.graph import StateGraph, START, END, MessagesState
from langgraph.checkpoint.memory import MemorySaver


# API í‚¤ ë“± í™˜ê²½ì„¤ì •
load_dotenv()
# AOAI_ENDPOINT = os.getenv("AOAI_ENDPOINT")
# AOAI_API_KEY = os.getenv("AOAI_API_KEY")
# AOAI_DEPLOY_GPT4O = os.getenv("AOAI_DEPLOY_GPT4O")
# AOAI_DEPLOY_GPT4O_MINI = os.getenv("AOAI_DEPLOY_GPT4O_MINI")
# AOAI_DEPLOY_EMBED_3_LARGE = os.getenv("AOAI_DEPLOY_EMBED_3_LARGE")
# AOAI_DEPLOY_EMBED_3_SMALL = os.getenv("AOAI_DEPLOY_EMBED_3_SMALL")
# AOAI_DEPLOY_EMBED_ADA = os.getenv("AOAI_DEPLOY_EMBED_ADA")
API_ENDPOINT = os.getenv("API_ENDPOINT")
API_SECRET = os.getenv("API_SECRET")
API_VERSION = os.getenv("API_VERSION")
AIRFLOW_URL = os.getenv("AIRFLOW_URL")
AIRFLOW_USERNAME = os.getenv("AIRFLOW_USERNAME")
AIRFLOW_PASSWORD = os.getenv("AIRFLOW_PASSWORD")

# llm ê°ì²´ ìƒì„±
# llm = AzureChatOpenAI(
#     azure_endpoint=AOAI_ENDPOINT,
#     azure_deployment=AOAI_DEPLOY_GPT4O,
#     api_version="2024-10-21",
#     api_key=AOAI_API_KEY
# )
llm = ChatOpenAI(model="ax4", base_url=API_ENDPOINT, api_key=API_SECRET)


class AirflowAuthManager:
    def __init__(self, airflow_url, username, password):
        self.airflow_url = airflow_url
        self.username = username
        self.password = password
        self._token = None
        self._token_expiry = 0

    def get_jwt_token(self):
        token_url = f"{self.airflow_url}/auth/token"
        payload = {"username": self.username, "password": self.password}
        response = requests.post(token_url, json=payload)
        access_token = response.json().get("access_token", None)
        if not access_token:
            print(f"í† í° ìƒì„± ì‹¤íŒ¨: {response.status_code} - {response.text}")
            return None
        else:
            return access_token

    def get_valid_token(self):
        """JWT í† í°ì„ ê°€ì ¸ì˜¤ê±°ë‚˜ ê°±ì‹ í•©ë‹ˆë‹¤."""
        current_time = time.time()

        # í† í°ì´ ì—†ê±°ë‚˜ ë§Œë£Œ 5ë¶„ ì „ì´ë©´ ê°±ì‹ 
        if not self._token or current_time >= (self._token_expiry - 300):
            self._token = self.get_jwt_token()
            if self._token:
                # JWT í† í°ì˜ ê¸°ë³¸ ë§Œë£Œ ì‹œê°„ì€ 24ì‹œê°„ (86400ì´ˆ)
                self._token_expiry = current_time + 86400
            else:
                raise Exception("JWT í† í° ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

        return self._token


def get_task_instances_in_group(
    airflow_base_url: str,
    dag_id: str,
    dag_run_id: str,
    task_group_id: str,
) -> t.List[t.Dict]:
    """[Helper] íŠ¹ì • Task Group ë‚´ì˜ ëª¨ë“  Task Instanceë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    instances_in_group = []
    endpoint = (
        f"{airflow_base_url}/{API_VERSION}/dags/{dag_id}/dagRuns/{dag_run_id}/taskInstances"
    )
    offset = 0
    limit = 100
    while True:
        # JWT í† í° ì‚¬ìš©
        token = auth_manager.get_valid_token()
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json",
        }
        params = {"limit": limit, "offset": offset}
        try:
            response = requests.get(endpoint, params=params, headers=headers)
            response.raise_for_status()
            data = response.json()
            task_instances = data.get("task_instances", [])
            if not task_instances:
                break
            # í´ë¼ì´ì–¸íŠ¸ ì¸¡ì—ì„œ Task Groupì— ì†í•œ Taskë§Œ í•„í„°ë§
            for ti in task_instances:
                if f"{task_group_id}." in ti.get("task_id", ""):
                    instances_in_group.append(ti)
            offset += len(task_instances)
        except requests.exceptions.RequestException as e:
            print(f"Error fetching tasks for group '{task_group_id}': {e}")
            raise
    return instances_in_group


def find_failed_groups_and_their_tasks(
    task_id_contains: str,
    logical_date_gte: t.Optional[str] = None,
    logical_date_lte: t.Optional[str] = None,
) -> t.Dict[str, t.List[t.Dict]]:
    """
    ì‹¤íŒ¨í•œ Taskê°€ í¬í•¨ëœ Task Groupì„ ì°¾ê³ , í•´ë‹¹ ê·¸ë£¹ ë‚´ì˜ ëª¨ë“  Task Instance ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        task_id_contains (str): ê²€ìƒ‰í•  Task IDì— í¬í•¨ëœ ë¬¸ìì—´
        logical_date_gte (t.Optional[str]): ì¡°íšŒ ì‹œì‘ ë…¼ë¦¬ì  ë‚ ì§œ (ISO 8601 í˜•ì‹)
        logical_date_lte (t.Optional[str]): ì¡°íšŒ ì¢…ë£Œ ë…¼ë¦¬ì  ë‚ ì§œ (ISO 8601 í˜•ì‹)

    Returns:
        t.Dict[str, t.List[t.Dict]]: Task Group ì‹ë³„ìë¥¼ Keyë¡œ,
                                     í•´ë‹¹ ê·¸ë£¹ ë‚´ Task Instance ë¦¬ìŠ¤íŠ¸ë¥¼ Valueë¡œ ê°–ëŠ” ë”•ì…”ë„ˆë¦¬.
    """
    airflow_base_url = AIRFLOW_URL
    # 1ë‹¨ê³„: ì‹¤íŒ¨í•œ Taskê°€ ì†í•œ Task Group ì‹ë³„
    print("--- 1ë‹¨ê³„: ì‹¤íŒ¨ Taskê°€ í¬í•¨ëœ Task Group ì‹ë³„ ì¤‘ ---")
    failed_task_groups = set()
    find_endpoint = f"{airflow_base_url}/{API_VERSION}/dags/~/dagRuns/~/taskInstances"
    params = {"state": ["failed"]}
    if logical_date_gte:
        params["logical_date_gte"] = logical_date_gte
    if logical_date_lte:
        params["logical_date_lte"] = logical_date_lte
    offset = 0
    limit = 100
    while True:
        # JWT í† í° ì‚¬ìš©
        token = auth_manager.get_valid_token()
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json",
        }
        params["offset"] = offset
        response = requests.get(find_endpoint, params=params, headers=headers)
        response.raise_for_status()
        data = response.json()
        task_instances = data.get("task_instances", [])
        if not task_instances:
            break
        for ti in task_instances:
            task_id = ti.get("task_id")
            if task_id and task_id_contains in task_id:
                last_dot_index = task_id.rfind(".")
                if last_dot_index != -1:
                    task_group_id = task_id[:last_dot_index]
                    failed_task_groups.add(
                        (ti.get("dag_id"), ti.get("dag_run_id"), task_group_id)
                    )
        offset += len(task_instances)
        if offset >= data.get("total_entries", 0):
            break
    if not failed_task_groups:
        print("âœ”ï¸ ì¡°ê±´ì— ë§ëŠ” ì‹¤íŒ¨ Task Groupì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return {}
    print(f"âœ”ï¸ ì´ {len(failed_task_groups)}ê°œì˜ ê³ ìœ í•œ Task Groupì„ ì‹ë³„í–ˆìŠµë‹ˆë‹¤.")
    # 2ë‹¨ê³„: ì‹ë³„ëœ ê° Task Groupì— ëŒ€í•´ ëª¨ë“  Task Instance ì¡°íšŒ
    print("\n--- 2ë‹¨ê³„: ì‹ë³„ëœ Group ë‚´ ëª¨ë“  Task Instance ì¡°íšŒ ì¤‘ ---")
    final_results = defaultdict(list)
    for dag_id, dag_run_id, task_group_id in failed_task_groups:
        print(f" -> '{task_group_id}' ê·¸ë£¹ì˜ Taskë“¤ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        instances = get_task_instances_in_group(
            airflow_base_url, dag_id, dag_run_id, task_group_id
        )
        group_key = f"{dag_id}::{dag_run_id}::{task_group_id}"
        final_results[group_key] = instances
    return dict(final_results)


def clear_specific_task_instances(
    dag_id: str,
    dag_run_id: str,
    task_ids: t.List[str],
    dry_run: bool = False,
) -> t.Dict:
    """
    íŠ¹ì • DAG Runì— ì†í•œ ì§€ì •ëœ Task Instance ëª©ë¡ì„ Clearí•©ë‹ˆë‹¤.

    Args:
        dag_id (str): ëŒ€ìƒ DAGì˜ ID
        dag_run_id (str): ëŒ€ìƒ DAG Runì˜ ID
        task_ids (t.List[str]): Clearí•  Taskë“¤ì˜ ID ë¦¬ìŠ¤íŠ¸
        dry_run (bool): Trueë¡œ ì„¤ì •í•˜ë©´ ì‹¤ì œë¡œ ì‹¤í–‰í•˜ì§€ ì•Šê³  ê²°ê³¼ë§Œ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.

    Returns:
        t.Dict: Clear ì‘ì—… ê²°ê³¼ (Clearëœ Task Instance ì •ë³´ í¬í•¨)
    """
    airflow_base_url = AIRFLOW_URL
    endpoint = f"{airflow_base_url}/{API_VERSION}/dags/{dag_id}/clearTaskInstances"
    payload = {
        "dag_run_id": dag_run_id,
        "task_ids": task_ids,
        "dry_run": dry_run,
        "only_failed": False,
    }
    print(
        f"ğŸ”„ DAG '{dag_id}'ì˜ Run '{dag_run_id}'ì— ì†í•œ Task {len(task_ids)}ê°œë¥¼ Clearí•˜ëŠ” ì¤‘..."
    )
    if dry_run:
        print(" (Dry Run ëª¨ë“œ: ì‹¤ì œë¡œ ì‹¤í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤)")
    try:
        # JWT í† í° ì‚¬ìš©
        token = auth_manager.get_valid_token()
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json",
        }
        response = requests.post(endpoint, json=payload, headers=headers)
        response.raise_for_status()
        result_data = response.json()
        return result_data
    except requests.exceptions.RequestException as e:
        print(f"âŒ Clear ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e.response.text if e.response else e}")
        raise


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
auth_manager = AirflowAuthManager(AIRFLOW_URL, AIRFLOW_USERNAME, AIRFLOW_PASSWORD)
checkpointer = MemorySaver()
# members = ["airflow", "sftp", "ftp", "eai", ...]
members = ["airflow"]
options = members + ["FINISH"]

# Supervisor í”„ë¡¬í”„íŠ¸
system_prompt = (
    "You are a supervisor tasked with managing a conversation between the"
    f" following workers: {members}. Given the following user request,"
    " respond with the worker to act next. Each worker will perform a"
    " task and respond with their results and status. When finished,"
    " respond with FINISH."
)


class Router(TypedDict):
    """Worker to route to next. If no workers needed, route to FINISH."""

    # 'Router' ë¼ëŠ” ì´ë¦„ì˜ ë°ì´í„° êµ¬ì¡° ì •ì˜ -> 'next' ë¼ëŠ” ê°ì²´ë¥¼ ê°€ì§€ê³  ìˆì–´ì•¼ í•¨
    # Literal íƒ€ì…ì€ ë³€ìˆ˜ê°€ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ê°’ì„ ë¯¸ë¦¬ ì •í•´ì§„ ì •í™•í•œ ìƒìˆ˜ ê°’ë“¤ë¡œ ì œí•œ
    next: Literal[*options]


class State(MessagesState):
    # ë‹¤ìŒ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•  Agentê°€ ëˆ„êµ¬ì¸ì§€ ì„¤ì •í•˜ê¸° ìœ„í•´ nextê°€ ì¶”ê°€ë¨
    next: str


def supervisor_node(state: State) -> Command[Literal[*members, "__end__"]]:
    # Return ê°’ì´ Stateê³  ì •í•´ì§„ edgeë¡œ ê°€ëŠ” ê²ƒì´ ì•„ë‹Œ Commandê°€ ë°˜í™˜ë¨
    messages = [
        {"role": "system", "content": system_prompt},
    ] + state["messages"]
    response = llm.with_structured_output(Router).invoke(messages)
    goto = response["next"]
    if goto == "FINISH":
        goto = END
    return Command(goto=goto, update={"next": goto})


def find_failed_groups_and_their_tasks_tool(
    task_id_contains: str,
    logical_date_gte: t.Optional[str] = None,
    logical_date_lte: t.Optional[str] = None,
) -> t.Dict[str, t.List[t.Dict]]:
    """Agentì—ì„œ ì‚¬ìš©í•  ë„êµ¬ - JWT í† í° ìë™ ì²˜ë¦¬"""
    return find_failed_groups_and_their_tasks(
        task_id_contains=task_id_contains,
        logical_date_gte=logical_date_gte,
        logical_date_lte=logical_date_lte,
    )


def clear_specific_task_instances_tool(
    dag_id: str,
    dag_run_id: str,
    task_ids: t.List[str],
    dry_run: bool = False,
) -> t.Dict:
    """Agentì—ì„œ ì‚¬ìš©í•  ë„êµ¬ - JWT í† í° ìë™ ì²˜ë¦¬"""
    return clear_specific_task_instances(
        dag_id=dag_id,
        dag_run_id=dag_run_id,
        task_ids=task_ids,
        dry_run=dry_run,
    )


airflow_agent = create_react_agent(
    llm,
    tools=[find_failed_groups_and_their_tasks_tool, clear_specific_task_instances_tool],
    prompt="""
    # Airflow ì‹¤íŒ¨ ì²˜ë¦¬ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸

    ## ì—­í•  ë° ëª©í‘œ

    ë‹¹ì‹ ì€ ì „ë¬¸ Airflow ì–´ì‹œìŠ¤í„´íŠ¸ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì£¼ìš” ëª©í‘œëŠ” ì‚¬ìš©ìê°€ ì‚¬ì „ ì •ì˜ëœ ë„êµ¬(tool)ë¥¼ ì‚¬ìš©í•˜ì—¬ Apache Airflow í™˜ê²½ì˜ ì‹¤íŒ¨í•œ Task Instanceë¥¼ ì‹ë³„í•˜ê³  í•´ê²°í•˜ë„ë¡ ë•ëŠ” ê²ƒì…ë‹ˆë‹¤.

    ë‹¹ì‹ ì€ ë¨¼ì € ë¬¸ì œë¥¼ ì§„ë‹¨(ì‹¤íŒ¨ íƒìƒ‰)í•˜ê³ , ì‚¬ìš©ìì˜ **ëª…ì‹œì ì¸ í™•ì¸**ì„ ë°›ì€ í›„ì— í•´ê²°ì±…(ì‹¤íŒ¨ Task clear)ì„ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.

    ***

    ## ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ (Available Tools)

    ë‹¹ì‹ ì€ ì•„ë˜ ë‘ ê°€ì§€ ë„êµ¬ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    ### 1. `find_failed_groups_and_their_tasks_tool`

    -   **ì„¤ëª…**: Task IDì— íŠ¹ì • í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ê³  'failed' ìƒíƒœì¸ Task Instanceë¥¼ ì°¾ìŠµë‹ˆë‹¤. ì´ ë„êµ¬ëŠ” ì‹¤íŒ¨í•œ Taskê°€ ì†í•œ Task Groupì„ ì‹ë³„í•˜ê³ , í•´ë‹¹ DAG Runì˜ í•´ë‹¹ Task Group ë‚´ì— ìˆëŠ” **ëª¨ë“ ** Task Instance(ì„±ê³µ, ì‹¤íŒ¨ ë“± ëª¨ë“  ìƒíƒœ í¬í•¨)ì˜ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    -   **íŒŒë¼ë¯¸í„°**:
        -   `task_id_contains` (str): ê²€ìƒ‰í•  Task IDì— í¬í•¨ëœ í‚¤ì›Œë“œ ë¬¸ìì—´.
        -   `logical_date_gte` (str, ì„ íƒ ì‚¬í•­): ì¡°íšŒ ì‹œì‘ ì‹œê°„ (ISO 8601 í˜•ì‹, ì˜ˆ: `2025-10-02T00:00:00Z`).
        -   `logical_date_lte` (str, ì„ íƒ ì‚¬í•­): ì¡°íšŒ ì¢…ë£Œ ì‹œê°„ (ISO 8601 í˜•ì‹, ì˜ˆ: `2025-10-02T23:59:59Z`).

    ### 2. `clear_specific_task_instances_tool`

    -   **ì„¤ëª…**: íŠ¹ì • DAG Run ë‚´ì—ì„œ ì§€ì •ëœ Task Instance ëª©ë¡ì˜ ìƒíƒœë¥¼ 'clear'í•©ë‹ˆë‹¤. ì´ ì‘ì—…ì€ Taskë¥¼ ì¬ì‹¤í–‰í•˜ë„ë¡ ë§Œë“¤ ìˆ˜ ìˆëŠ” **ì‹¤í–‰ ì‘ì—…**ì´ë¯€ë¡œ, ë°˜ë“œì‹œ ì‚¬ìš©ìì˜ í™•ì¸ì„ ë°›ì€ í›„ì—ë§Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    -   **íŒŒë¼ë¯¸í„°**:
        -   `dag_id` (str): ëŒ€ìƒ DAGì˜ ID.
        -   `dag_run_id` (str): ëŒ€ìƒ DAG Runì˜ ID.
        -   `task_ids` (List[str]): Clearí•  Taskë“¤ì˜ ID ëª©ë¡.

    ***

    ## ì‘ì—… íë¦„ ë° ì§€ì‹œì‚¬í•­

    ë‹¹ì‹ ì€ ë‹¤ìŒì˜ ì‘ì—… íë¦„ì„ ë°˜ë“œì‹œ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.

    1.  **ìš”ì²­ íŒŒì•…**: ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì£¼ì˜ ê¹Šê²Œ ë“£ê³  "ì°¾ì•„ì¤˜", "ê²€ìƒ‰í•´ì¤˜"ì™€ ê°™ì€ íƒìƒ‰ ìš”ì²­ì¸ì§€ íŒŒì•…í•©ë‹ˆë‹¤.
    2.  **ì‹¤íŒ¨ íƒìƒ‰**: ì‚¬ìš©ìê°€ ì‹¤íŒ¨ ì¡°ì‚¬ë¥¼ ìš”ì²­í•˜ë©´, `find_failed_groups_and_their_tasks_tool` ë„êµ¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì œê³µí•˜ëŠ” í‚¤ì›Œë“œë‚˜ ë‚ ì§œ ë²”ìœ„ë¥¼ íŒŒë¼ë¯¸í„°ë¡œ ì •í™•íˆ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.
    3.  **ê²°ê³¼ ìš”ì•½**: íƒìƒ‰ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ëª…í™•í•˜ê²Œ ìš”ì•½í•˜ì—¬ ë³´ê³ í•©ë‹ˆë‹¤. ì–´ë–¤ Task Groupì—ì„œ ëª‡ ê°œì˜ Taskê°€ ë°œê²¬ë˜ì—ˆê³ , ê·¸ì¤‘ ì‹¤íŒ¨í•œ TaskëŠ” ë¬´ì—‡ì¸ì§€ ë“±ì„ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤.
    4.  **ì‹¤í–‰ í™•ì¸ (ë§¤ìš° ì¤‘ìš”)**: Taskë¥¼ clearí•˜ê¸° ì „, **ë°˜ë“œì‹œ** ì‚¬ìš©ìì—ê²Œ ëª…ì‹œì ì¸ ì‹¤í–‰ í—ˆê°€ë¥¼ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, **"ìœ„ì—ì„œ ì°¾ì€ Taskë“¤ì„ clear í• ê¹Œìš”?"** ì™€ ê°™ì´ ëª…í™•í•˜ê²Œ ì§ˆë¬¸í•´ì•¼ í•©ë‹ˆë‹¤.
    5.  **ì‘ì—… ì‹¤í–‰**: ì‚¬ìš©ìê°€ "ë„¤", "ì‹¤í–‰í•˜ì„¸ìš”", "clear í•´ì£¼ì„¸ìš”" ë“±ìœ¼ë¡œ ê¸ì •ì ìœ¼ë¡œ ë‹µë³€í•˜ë©´, `clear_specific_task_instances_tool` ë„êµ¬ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤. ì´ë•Œ, ì´ì „ `find` ë‹¨ê³„ì—ì„œ ì–»ì€ `dag_id`, `dag_run_id`, `task_ids` ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ íŒŒë¼ë¯¸í„°ë¡œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    6.  **ìµœì¢… ë³´ê³ **: Clear ì‘ì—…ì˜ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ë³´ê³ í•˜ê³  ëŒ€í™”ë¥¼ ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤.

    ***

    ## ì œì•½ ì¡°ê±´

    -   ì£¼ì–´ì§„ ë‘ ê°€ì§€ ë„êµ¬ ì™¸ì— ë‹¤ë¥¸ ê¸°ëŠ¥ì´ë‚˜ ì •ë³´ë¥¼ ì•„ëŠ” ê²ƒì²˜ëŸ¼ í–‰ë™í•˜ì§€ ë§ˆì„¸ìš”.
    -   ì‚¬ìš©ìì˜ ìš”ì²­ì´ ëª¨í˜¸í•  ê²½ìš°, ì¶”ì¸¡í•˜ì§€ ë§ê³  ë˜ë¬¼ì–´ì„œ ëª…í™•íˆ í•˜ì„¸ìš”.
    -   **ì ˆëŒ€ë¡œ ì‚¬ìš©ìì˜ í—ˆê°€ ì—†ì´ `clear_specific_task_instances_tool` ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”.**

    ***

    ## ëŒ€í™” ì˜ˆì‹œ

    **User**:
    ì–´ì œ ì‹¤íŒ¨í•œ íƒœìŠ¤í¬ ì¤‘ì— 'user_processing' ì´ë¼ëŠ” í‚¤ì›Œë“œê°€ ë“¤ì–´ê°„ ì• ë“¤ ì¢€ ì°¾ì•„ì¤˜.

    **Agent (Thought)**:
    ì‚¬ìš©ìê°€ 'ì–´ì œ'ë¼ëŠ” ì‹œê°„ ë²”ìœ„ì™€ 'user_processing'ì´ë¼ëŠ” í‚¤ì›Œë“œë¡œ ì‹¤íŒ¨í•œ íƒœìŠ¤í¬ë¥¼ ì°¾ì•„ë‹¬ë¼ê³  ìš”ì²­í–ˆë‹¤. `find_failed_groups_and_their_tasks_tool` ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ê² ë‹¤. `logical_date`ëŠ” ì–´ì œ ë‚ ì§œë¡œ ì„¤ì •í•œë‹¤.
    > Tool Call: `find_failed_groups_and_their_tasks_tool(task_id_contains='user_processing', logical_date_gte='2025-10-02T00:00:00Z', logical_date_lte='2025-10-02T23:59:59Z')`

    **Agent (Response)**:
    ë„¤, ì–´ì œ ë‚ ì§œë¡œ 'user_processing'ì„ í¬í•¨í•˜ëŠ” ì‹¤íŒ¨ Taskë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.
    `user_processing_group` Task Groupì—ì„œ ì´ 5ê°œì˜ Taskê°€ ë°œê²¬ë˜ì—ˆìœ¼ë©°, ê·¸ì¤‘ `user_processing_group.transform` Taskê°€ 'failed' ìƒíƒœì…ë‹ˆë‹¤. ì „ì²´ ëª©ë¡ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
    -   `user_processing_group.extract` (state: success)
    -   `user_processing_group.transform` (state: failed)
    -   `user_processing_group.load_summary` (state: upstream_failed)
    -   `user_processing_group.load_details` (state: upstream_failed)
    -   `user_processing_group.validate` (state: upstream_failed)

    ì´ Taskë“¤ì„ clear í• ê¹Œìš”?

    **User**:
    ë„¤, clear í•´ì£¼ì„¸ìš”.

    **Agent (Thought)**:
    ì‚¬ìš©ìê°€ clearë¥¼ í™•ì¸í–ˆë‹¤. ì´ì „ ë‹¨ê³„ì—ì„œ ì–»ì€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ `clear_specific_task_instances_tool` ë„êµ¬ë¥¼ í˜¸ì¶œí•œë‹¤.
    > Tool Call: `clear_specific_task_instances_tool(dag_id='user_pipeline', dag_run_id='scheduled__2025-10-02T...', task_ids=['user_processing_group.extract', 'user_processing_group.transform', ...])`

    **Agent (Response)**:
    ë„¤, ìš”ì²­í•˜ì‹  `user_processing_group`ì— ì†í•œ 5ê°œ Taskì˜ ìƒíƒœë¥¼ clear í–ˆìŠµë‹ˆë‹¤. ìŠ¤ì¼€ì¤„ëŸ¬ì— ì˜í•´ ê³§ ì¬ì‹¤í–‰ë  ê²ƒì…ë‹ˆë‹¤.
    """,
)


def airflow_node(state: State) -> Command[Literal["supervisor"]]:
    result = airflow_agent.invoke(state)
    return Command(
        update={
            "messages": [
                HumanMessage(
                    content=result["messages"][-1].content,
                    name="airflow",
                ),
            ],
        },
        goto="supervisor",  # ì—…ë¬´ ìˆ˜í–‰ í›„, gotoë¥¼ ìŠˆí¼ë°”ì´ì €ë¡œ ì„¤ì •í•´ ë³´ê³ í•  ìˆ˜ ìˆë„ë¡
    )


builder = StateGraph(State)
builder.add_edge(START, "supervisor")
builder.add_node("supervisor", supervisor_node)
builder.add_node("airflow", airflow_node)
# builder.add_node("sftp", airflow_node)
# builder.add_node("ftp", airflow_node)
# builder.add_node("eai", airflow_node)
graph = builder.compile(checkpointer=checkpointer)
config = {"configurable": {"thread_id": "123456"}, "recursion_limit": 10}

for s in graph.stream(
    {
        "messages": [
            (
                "user",
                "'task_2_fails'ê°€ ë“¤ì–´ê°„ airflow ì‘ì—…ì´ ì‹¤íŒ¨í–ˆìœ¼ë©´ ë¬»ì§€ ë§ê³  ì¬ìˆ˜í–‰í•´ì¤˜, ì‹œì‘ì‹œê°„ì€ '2025-10-01T00:00:00Z'ì´ê³  ì¢…ë£Œì‹œê°„ì€ '2025-10-01T23:59:59Z'ì•¼",
            )
        ]
    },
    config=config,
    subgraphs=True,
):
    print(s)
    print("----")
